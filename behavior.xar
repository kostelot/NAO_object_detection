<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.ald.softbankrobotics.com/schema/choregraphe/project.xsd" xar_version="3">
  <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
    <bitmap>media/images/box/root.png</bitmap>
    <script language="4">
      <content>
        <![CDATA[]]>
      </content>
    </script>
    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
    <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
    <Timeline enable="0">
      <BehaviorLayer name="behavior_layer1">
        <BehaviorKeyframe name="keyframe1" index="1">
          <Diagram>
            <Box name="object_detection" id="2" localization="8" tooltip="" x="223" y="309">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import struct
import socket
from naoqi import ALProxy
import cv2
import numpy as np
import time

# Graceful exit function
def graceful_exit():
    print("\nGracefully exiting...")
    if video_client:
        video_device.unsubscribe(video_client)
    if sock:
        sock.close()

print('Script started')

robotIP = "192.168.0.113"
PORT = 9559

# Disable autonomy
life = ALProxy("ALAutonomousLife", robotIP, PORT)
life.setState("disabled")

# Disable basic awareness
awareness = ALProxy("ALBasicAwareness", robotIP, PORT)
awareness.stopAwareness()

# Motion control
motion = ALProxy("ALMotion", robotIP, PORT)
motion.wakeUp()
motion.setStiffnesses("Head", 1.0)

# Fix head position
motion.setAngles("HeadYaw", 0.0, 0.1)
motion.setAngles("HeadPitch", 0.25, 0.1)

# Setup camera, socket, and proxies
video_device = ALProxy("ALVideoDevice", "192.168.0.113", 9559)


video_client = video_device.subscribeCamera("yolo_feed", 0, 2, 11, 20)
print("Subscribed to camera:", video_client)

sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.connect(("192.168.0.117", 5000))  # Connect to the PC server IP

# ALProxy for text-to-speech (for NAO to speak)
tts = ALProxy("ALTextToSpeech", "192.168.0.113", 9559)

# Main loop
try:
    while True:
        # Capture the image and send it to the server
        frame = video_device.getImageRemote(video_client)

        # Check for valid frame data
        if not frame or not frame[6] or len(frame[6]) < frame[0] * frame[1] * 3:
            print("Invalid frame data received. Skipping.")
            continue

        print("Image captured, processing...")

        # Get width and height
        width, height = frame[0], frame[1]

        # Convert byte array to NumPy array and reshape
        img_data = np.frombuffer(frame[6], dtype=np.uint8)
        img = img_data.reshape((height, width, 3))

        # Encode the image as JPEG
        success, encoded_img = cv2.imencode('.jpg', img)
        if not success:
            print("Failed to encode image. Skipping.")
            continue

        data = encoded_img.tobytes()
        size = len(data)

        # Send the size and image data
        try:
            print("Sending image data...")
            sock.sendall(struct.pack('>I', size))  # Send image size
            sock.sendall(data)  # Send image data
            print("Image data sent successfully!")

            # Wait for server response (object detection result)
            data_received = sock.recv(1024)  # Adjust buffer size if needed
            if data_received:
                # Decode and log the received message
                result_message = data_received.decode('utf-8')
                print("Received raw message: {!r}".format(result_message))  # Show raw format with special characters

                # Strip any extra spaces or newline characters
                result_message = result_message.strip()
                print("Processed result message: {!r}".format(result_message))

                # If no objects detected, handle it gracefully
               # if not result_message or result_message == "No objects detected.":
               #     result_message = "I couldn't detect anything. Please try again."

                # Ensure result_message is a valid string and not empty
                if isinstance(result_message, unicode):  # Convert Unicode to regular string in Python 2
                    result_message = result_message.encode('utf-8')
                if isinstance(result_message, str) and result_message.strip():  # Check for non-empty result
                    try:
                        result_message = result_message.encode('ascii', 'ignore')  # Remove non-ASCII characters
                        print("Final message to NAO: {!r}".format(result_message))
                        if result_message=="No objects detected.":
                            continue
                        tts.say(str(result_message))  # Ensure it's a string
                    except Exception as e:
                        print("Error speaking result:", e)
                else:
                    print("No valid result to speak.")
            else:
                print("No data received from server.")

        except socket.timeout:
            print("Socket timeout occurred. No response from PC.")
            continue

except KeyboardInterrupt:
    # Handle manual interruption (e.g., Ctrl+C)
    print("\nKeyboardInterrupt received. Exiting...")
    graceful_exit()

except Exception as e:
    print("An error occurred:", e)
    graceful_exit()

finally:
    # Ensure cleanup regardless of how the loop ends
    graceful_exit()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
            </Box>
            <Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="2" />
            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
          </Diagram>
        </BehaviorKeyframe>
      </BehaviorLayer>
    </Timeline>
  </Box>
</ChoregrapheProject>
